#!/usr/bin/env python3
import argparse
from PIL import Image, ImageDraw, ImageFont
import actfw_core
from actfw_core.task import Pipe, Consumer
from actfw_core.system import get_actcast_firmware_type, find_csi_camera_device, find_usb_camera_device
from actfw_core.capture import V4LCameraCapture
from actfw_core.unicam_isp_capture import UnicamIspCapture
import actfw_raspberrypi
from actfw_raspberrypi.vc4 import Display
import numpy as np
from model import Model

(CAPTURE_WIDTH, CAPTURE_HEIGHT) = (224, 224)  # capture image size
(DISPLAY_WIDTH, DISPLAY_HEIGHT) = (640, 480)  # display area size


class Classifier(Pipe):

    def __init__(self, capture_size):
        super(Classifier, self).__init__()
        self.model = Model()
        self.capture_size = capture_size

    def proc(self, frame):
        rgb_image = Image.frombuffer('RGB', self.capture_size, frame.getvalue(), 'raw', 'RGB')
        rgb_image = rgb_image.resize((CAPTURE_WIDTH, CAPTURE_HEIGHT))
        input_image = np.asarray(rgb_image).reshape(1, CAPTURE_WIDTH, CAPTURE_HEIGHT, 3).astype(np.float32)
        probs, = self.model.MobileNet_v2(input_image)
        return (rgb_image, probs[0][1:])


class Presenter(Consumer):

    def __init__(self, settings, preview_window, cmd):
        super(Presenter, self).__init__()
        self.settings = settings
        self.preview_window = preview_window
        self.cmd = cmd
        self.font = ImageFont.truetype(font='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', size=18)
        with open('labels.txt') as f:
            self.labels = f.read().splitlines()

    def proc(self, images):
        rgb_image, probs = images
        top1 = probs.argsort()[-1]
        if probs[top1] > self.settings['threshold']:
            actfw_core.notify([{'prob': float(probs[top1]), 'label': self.labels[top1]}])
        self.cmd.update_image(rgb_image)  # update `Take Photo` image
        actfw_core.heartbeat()
        if self.preview_window is not None:
            draw = ImageDraw.Draw(rgb_image)
            draw.text((0, 0), "{:>6.2f}% {}".format(100 * probs[top1], self.labels[top1]), font=self.font, fill=(0, 255, 0))
            self.preview_window.blit(rgb_image.tobytes())
            self.preview_window.update()

def setup_camera_capture(use_usb_camera):
    framerate = 15
    device = find_usb_camera_device() if use_usb_camera else find_csi_camera_device()

    if get_actcast_firmware_type() == "raspberrypi-bullseye" and not use_usb_camera:
        # Use UnicamIspCapture on Raspberry Pi OS Bullseye
        cap = UnicamIspCapture(unicam=device, size=(CAPTURE_WIDTH, CAPTURE_HEIGHT), framerate=framerate)
    else:
        # Use V4LCameraCapture on Raspberry Pi OS Buster or use USB camera
        cap = V4LCameraCapture(device, (CAPTURE_WIDTH, CAPTURE_HEIGHT), framerate, format_selector=V4LCameraCapture.FormatSelector.PROPER)

    return cap

def main(args):

    # Actcast application
    app = actfw_core.Application()

    # Load act setting
    settings = app.get_settings({'display': True, 'threshold': 0.1, 'use_usb_camera': False})

    # CommandServer (for `Take Photo` command)
    cmd = actfw_core.CommandServer()
    app.register_task(cmd)

    cap = setup_camera_capture(settings['use_usb_camera'])
    capture_size = cap.capture_size()
    app.register_task(cap)

    # Classifier task
    conv = Classifier(capture_size)
    app.register_task(conv)

    def run(preview_window=None):

        # Presentation task
        pres = Presenter(settings, preview_window, cmd)
        app.register_task(pres)

        # Make task connection
        cap.connect(conv)  # from `cap` to `conv`
        conv.connect(pres)  # from `conv` to `pres`

        # Start application
        app.run()

    if settings['display']:
        with Display() as display:
            display_width, display_height = display.size()
            scale = min(float(display_width / CAPTURE_WIDTH), float(display_height / CAPTURE_WIDTH))
            width = int(scale * CAPTURE_WIDTH)
            height = int(scale * CAPTURE_HEIGHT)
            left = (display_width - width) // 2
            upper = (display_height - height) // 2
            # layer must be between 1 and 16
            layer = 16
            with display.open_window((left, upper, width, height), (CAPTURE_WIDTH, CAPTURE_HEIGHT), layer) as preview_window:
                run(preview_window)
    else:
        run()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='example: 1000 class classification')
    main(parser.parse_args())
