#!/usr/bin/env python3
import argparse
from PIL import Image, ImageDraw, ImageFont
import actfw_core
from actfw_core.task import Pipe, Consumer
from actfw_core.capture import V4LCameraCapture
import actfw_raspberrypi
from actfw_raspberrypi.vc4 import Display
import numpy as np
from model import Model

(CAPTURE_WIDTH, CAPTURE_HEIGHT) = (224, 224)  # capture image size
(DISPLAY_WIDTH, DISPLAY_HEIGHT) = (640, 480)  # display area size


class Classifier(Pipe):

    def __init__(self, capture_size):
        super(Classifier, self).__init__()
        self.model = Model()
        self.capture_size = capture_size

    def proc(self, frame):
        rgb_image = Image.frombuffer('RGB', self.capture_size, frame.getvalue(), 'raw', 'RGB')
        rgb_image = rgb_image.resize((CAPTURE_WIDTH, CAPTURE_HEIGHT))
        input_image = np.asarray(rgb_image).reshape(1, CAPTURE_WIDTH, CAPTURE_HEIGHT, 3).astype(np.float32)
        probs, = self.model.MobileNet_v2(input_image)
        return (rgb_image, probs[0][1:])


class Presenter(Consumer):

    def __init__(self, settings, preview_window, cmd):
        super(Presenter, self).__init__()
        self.settings = settings
        self.preview_window = preview_window
        self.cmd = cmd
        self.font = ImageFont.truetype(font='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', size=18)
        with open('labels.txt') as f:
            self.labels = f.read().splitlines()

    def proc(self, images):
        rgb_image, probs = images
        top1 = probs.argsort()[-1]
        if probs[top1] > self.settings['threshold']:
            actfw_core.notify([{'prob': float(probs[top1]), 'label': self.labels[top1]}])
        self.cmd.update_image(rgb_image)  # update `Take Photo` image
        actfw_core.heartbeat()
        if self.preview_window is not None:
            draw = ImageDraw.Draw(rgb_image)
            draw.text((0, 0), "{:>6.2f}% {}".format(100 * probs[top1], self.labels[top1]), font=self.font, fill=(0, 255, 0))
            self.preview_window.blit(rgb_image.tobytes())
            self.preview_window.update()


def main(args):

    # Actcast application
    app = actfw_core.Application()

    # Load act setting
    settings = app.get_settings({'display': True, 'threshold': 0.8})

    # CommandServer (for `Take Photo` command)
    cmd = actfw_core.CommandServer()
    app.register_task(cmd)

    # Capture task
    cap = V4LCameraCapture('/dev/video0', (CAPTURE_WIDTH, CAPTURE_HEIGHT), 15, format_selector=V4LCameraCapture.FormatSelector.PROPER)
    capture_size = cap.capture_size()
    app.register_task(cap)

    # Classifier task
    conv = Classifier(capture_size)
    app.register_task(conv)

    def run(preview_window=None):

        # Presentation task
        pres = Presenter(settings, preview_window, cmd)
        app.register_task(pres)

        # Make task connection
        cap.connect(conv)  # from `cap` to `conv`
        conv.connect(pres)  # from `conv` to `pres`

        # Start application
        app.run()

    if settings['display']:
        with Display() as display:
            display_width, display_height = display.size()
            scale = min(float(display_width / CAPTURE_WIDTH), float(display_height / CAPTURE_WIDTH))
            width = int(scale * CAPTURE_WIDTH)
            height = int(scale * CAPTURE_HEIGHT)
            left = (display_width - width) // 2
            upper = (display_height - height) // 2
            with display.open_window((left, upper, width, height), (CAPTURE_WIDTH, CAPTURE_HEIGHT), 1000) as preview_window:
                run(preview_window)
    else:
        run()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='example: 1000 class classification')
    main(parser.parse_args())
